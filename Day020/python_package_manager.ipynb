{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "1. Read this url and find the 10 most frequent words. romeo_and_juliet = 'http://www.gutenberg.org/files/1112/1112.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 10 most frequent words are [('the', 766), ('I', 583), ('and', 555), ('to', 533), ('of', 487), ('a', 460), ('in', 341), ('is', 334), ('you', 318), ('my', 310)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "url = 'http://www.gutenberg.org/files/1112/1112.txt'  \n",
    "response = requests.get(url)\n",
    "\n",
    "file = response.text\n",
    "file = re.sub(r'[^\\w\\s]','',file)\n",
    "\n",
    "words = file.split()\n",
    "words_count = {}\n",
    "\n",
    "for i in words:\n",
    "    words_count[i] = words_count.get(i,0) + 1\n",
    "    \n",
    "sorted_words = sorted(words_count.items(),key =lambda x:x[1], reverse= True)\n",
    "\n",
    "top_words = [(i[0],i[1]) for i in sorted_words]\n",
    "\n",
    "print('The 10 most frequent words are', top_words[:10])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    " Read the cats API and cats_api = 'https://api.thecatapi.com/v1/breeds' and find :\n",
    "   1. the min, max, mean, median, standard deviation of cats' weight in metric units.\n",
    "   2. the min, max, mean, median, standard deviation of cats' lifespan in years.\n",
    "   3. Create a frequency table of country and breed of cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "response = requests.get(cats_api)\n",
    "response.status_code == 200\n",
    "cat_breeds = response.json()\n",
    "\n",
    "cat_weight_metric = []\n",
    "for i in range(len(cat_breeds)):\n",
    "  cat_weight_metric.append(cat_breeds[i]['weight']['metric'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. UCI is one of the most common places to get data sets for data science and machine learning. Read the content of UCI (https://archive.ics.uci.edu/ml/datasets.php). Without additional libraries it will be difficult, so you may try it with BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "\n",
    "response = requests.get(url)\n",
    "html_content = response.content\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "\n",
    "table = soup.find('table', {'border': '1'})\n",
    "\n",
    "\n",
    "rows = table.find_all('tr')[1:]\n",
    "for row in rows:\n",
    "    cells = row.find_all('td')\n",
    "    name = cells[0].text.strip()\n",
    "    \n",
    "    print(f'{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArewaDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "70474970a143700744fd95cb5146c78a729df9662c726c4b2793fd9cfb5786fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
